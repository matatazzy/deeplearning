{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6813b31e",
   "metadata": {
    "lang": "en"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from easydict import EasyDict\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.nn import CrossEntropyLoss, NLLLoss # 损失函数定义\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import timm\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c29a85b",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53762d40",
   "metadata": {},
   "source": [
    "在当前文件夹下查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9910019",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 驱动器 D 中的卷是 软件\n",
      " 卷的序列号是 20BD-F941\n",
      "\n",
      " D:\\Jupyter Notebook\\DeepLearning 的目录\n",
      "\n",
      "2023/11/15  23:37    <DIR>          .\n",
      "2023/11/09  10:12    <DIR>          ..\n",
      "2023/08/25  09:39             3,238 .gitignore\n",
      "2023/11/08  17:21    <DIR>          .ipynb_checkpoints\n",
      "2023/08/09  09:33         3,746,322 2_CNN架构的视觉骨架网络.ipynb\n",
      "2023/11/15  22:43            36,343 2022年计算机视觉SOTA实践.ipynb\n",
      "2023/08/09  09:33         2,581,419 3_Transformer架构的视觉骨架网络.ipynb\n",
      "2023/08/09  09:33            40,317 3_数据增强练习.ipynb\n",
      "2023/11/15  23:37            45,070 beasline学习 （第二次）.ipynb\n",
      "2023/11/09  10:13    <DIR>          Data\n",
      "2023/11/10  10:11    <DIR>          test\n",
      "               6 个文件      6,452,709 字节\n",
      "               5 个目录 215,865,229,312 可用字节\n"
     ]
    }
   ],
   "source": [
    "# 查看当前文件夹下的文件\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d0f80bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 驱动器 D 中的卷是 软件\n",
      " 卷的序列号是 20BD-F941\n",
      "\n",
      " D:\\Jupyter Notebook\\DeepLearning\\Data 的目录\n",
      "\n",
      "2023/11/09  10:13    <DIR>          .\n",
      "2023/11/15  23:37    <DIR>          ..\n",
      "2023/11/09  10:13    <DIR>          digit-recognizer\n",
      "               0 个文件              0 字节\n",
      "               3 个目录 215,865,229,312 可用字节\n"
     ]
    }
   ],
   "source": [
    "%ls .\\Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c068fede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 驱动器 D 中的卷是 软件\n",
      " 卷的序列号是 20BD-F941\n",
      "\n",
      " D:\\Jupyter Notebook\\DeepLearning\\Data\\digit-recognizer 的目录\n",
      "\n",
      "2023/11/09  10:13    <DIR>          .\n",
      "2023/11/09  10:13    <DIR>          ..\n",
      "2023/11/08  17:27           240,909 sample_submission.csv\n",
      "2023/11/08  17:27        51,118,296 test.csv\n",
      "2023/11/08  17:27        76,775,041 train.csv\n",
      "               3 个文件    128,134,246 字节\n",
      "               2 个目录 215,865,229,312 可用字节\n"
     ]
    }
   ],
   "source": [
    "%ls .\\Data\\digit-recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698bafed",
   "metadata": {},
   "source": [
    "数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3417715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./Data/digit-recognizer/train.csv\")\n",
    "test = pd.read_csv(\"./Data/digit-recognizer/test.csv\")\n",
    "submission = pd.read_csv(\"./Data/digit-recognizer/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283417e9",
   "metadata": {},
   "source": [
    "查看数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5df41da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "\n",
       "[2 rows x 785 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2) # 图片直接存在pixel中 28*28=784"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c41238",
   "metadata": {},
   "source": [
    "查看图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16a219c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x154c8318370>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAa20lEQVR4nO3df3BU9f3v8deGHwtqsjGEZLMSMKBCFUlvqaT5ohQllxBnGBC+vf7qHXAcHDF4hdTqpKMibWfSYr/Wr94I/7Sk3hFQ7whcGUsHgwljDXSIMFxua76EpiWWJNTcIRuChEg+9w+u2y4k4Fl2eWeX52PmzJDd88l5e9zx6ckuJz7nnBMAAFdYmvUAAICrEwECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmhlsPcL7+/n4dO3ZM6enp8vl81uMAADxyzqm7u1uhUEhpaYNf5wy5AB07dkz5+fnWYwAALlNra6vGjRs36PNDLkDp6emSpDt1r4ZrhPE0AACvvlSfPtL7kf+eDyZhAaqurtZLL72k9vZ2FRYW6rXXXtOMGTMuue6rH7sN1wgN9xEgAEg6//8Oo5d6GyUhH0J46623VFFRodWrV+uTTz5RYWGhSktLdfz48UQcDgCQhBISoJdfflnLli3TI488oltvvVXr16/XNddco1//+teJOBwAIAnFPUBnzpxRY2OjSkpK/nGQtDSVlJSooaHhgv17e3sVDoejNgBA6ot7gD7//HOdPXtWubm5UY/n5uaqvb39gv2rqqoUCAQiG5+AA4Crg/lfRK2srFRXV1dka21ttR4JAHAFxP1TcNnZ2Ro2bJg6OjqiHu/o6FAwGLxgf7/fL7/fH+8xAABDXNyvgEaOHKnp06ertrY28lh/f79qa2tVXFwc78MBAJJUQv4eUEVFhZYsWaJvf/vbmjFjhl555RX19PTokUceScThAABJKCEBuv/++/X3v/9dL7zwgtrb2/XNb35TO3bsuOCDCQCAq5fPOeesh/hn4XBYgUBAs7WAOyEAQBL60vWpTtvU1dWljIyMQfcz/xQcAODqRIAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwMtx4AALy4/vdZntdsLtgV07EKf/6E5zXBf/84pmNdjbgCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDNSAGZyGzI8r3k9/33Pa/rcCM9rJMnnYlqGr4krIACACQIEADAR9wC9+OKL8vl8UduUKVPifRgAQJJLyHtAt912mz744IN/HGQ4bzUBAKIlpAzDhw9XMBhMxLcGAKSIhLwHdPjwYYVCIU2cOFEPP/ywjh49Oui+vb29CofDURsAIPXFPUBFRUWqqanRjh07tG7dOrW0tOiuu+5Sd3f3gPtXVVUpEAhEtvz8/HiPBAAYguIeoLKyMn3ve9/TtGnTVFpaqvfff18nTpzQ22+/PeD+lZWV6urqimytra3xHgkAMAQl/NMBmZmZuuWWW9Tc3Dzg836/X36/P9FjAACGmIT/PaCTJ0/qyJEjysvLS/ShAABJJO4Bevrpp1VfX6+//OUv+vjjj3Xfffdp2LBhevDBB+N9KABAEov7j+A+++wzPfjgg+rs7NTYsWN15513as+ePRo7dmy8DwUASGJxD9DmzZvj/S0BJIE/ry32vGbzuH/zvMbv8/6e8Xc+ie0nMKGaQ57XnI3pSFcn7gUHADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJhI+C+kA5B8/u8j3m8s2vDgLzyvuS5tlOc1L3Xe6nlN7tLPPa+RpLPhcEzr8PVwBQQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT3A0bSGHDJt8U07oFqz70vCYQw52tD54563nNtl/c43lNZmeD5zVIPK6AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT3IwUSBJ9c7/tec09/1Yf07Eqsj6NaZ1Xy9Y+5XnN2De4sWiq4AoIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDBzUgBAx3/7V88r2l89r97XtMv53mNJP1H3xnPax7943/1vCZvy589r/nS8woMVVwBAQBMECAAgAnPAdq9e7fmz5+vUCgkn8+nrVu3Rj3vnNMLL7ygvLw8jR49WiUlJTp8+HC85gUApAjPAerp6VFhYaGqq6sHfH7t2rV69dVXtX79eu3du1fXXnutSktLdfr06cseFgCQOjx/CKGsrExlZWUDPuec0yuvvKLnnntOCxYskCS98cYbys3N1datW/XAAw9c3rQAgJQR1/eAWlpa1N7erpKSkshjgUBARUVFamgY+Nfo9vb2KhwOR20AgNQX1wC1t7dLknJzc6Mez83NjTx3vqqqKgUCgciWn58fz5EAAEOU+afgKisr1dXVFdlaW1utRwIAXAFxDVAwGJQkdXR0RD3e0dERee58fr9fGRkZURsAIPXFNUAFBQUKBoOqra2NPBYOh7V3714VFxfH81AAgCTn+VNwJ0+eVHNzc+TrlpYWHThwQFlZWRo/frxWrlypn/70p7r55ptVUFCg559/XqFQSAsXLozn3ACAJOc5QPv27dPdd98d+bqiokKStGTJEtXU1OiZZ55RT0+PHnvsMZ04cUJ33nmnduzYoVGjRsVvagBA0vM552K7W2GChMNhBQIBzdYCDfeNsB4HuKThN473vGb29v/jeU3F9d7vKBLrzUgLG5Z4XpP/r4diOhZSz5euT3Xapq6urou+r2/+KTgAwNWJAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJjz/OgYglQ3LzfG8ZtZ7f/K8ZuX1/+F5jeTzvKLly9MxHEe69v30mNYBXnAFBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4GakwD/LuM7zkoqsTxMwSHys/Nb8mNZldTbEeRLgQlwBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmuBkpUtLwcTfEtG7G//R+Y9E0+WI6ller2oo8r3FfnE7AJEB8cAUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjgZqRIScfXXxvTuh9l/2/Pa/pjOM5Tx2Z6XtPyXe//v9h/6pTnNcCVwhUQAMAEAQIAmPAcoN27d2v+/PkKhULy+XzaunVr1PNLly6Vz+eL2ubNmxeveQEAKcJzgHp6elRYWKjq6upB95k3b57a2toi26ZNmy5rSABA6vH8IYSysjKVlZVddB+/369gMBjzUACA1JeQ94Dq6uqUk5OjyZMna/ny5ers7Bx0397eXoXD4agNAJD64h6gefPm6Y033lBtba1+/vOfq76+XmVlZTp79uyA+1dVVSkQCES2/Pz8eI8EABiC4v73gB544IHIn2+//XZNmzZNkyZNUl1dnebMmXPB/pWVlaqoqIh8HQ6HiRAAXAUS/jHsiRMnKjs7W83NzQM+7/f7lZGREbUBAFJfwgP02WefqbOzU3l5eYk+FAAgiXj+EdzJkyejrmZaWlp04MABZWVlKSsrS2vWrNHixYsVDAZ15MgRPfPMM7rppptUWloa18EBAMnNc4D27dunu+++O/L1V+/fLFmyROvWrdPBgwf1m9/8RidOnFAoFNLcuXP1k5/8RH6/P35TAwCSnucAzZ49W865QZ//3e9+d1kDAecbPu4Gz2v+8w2fJmCSgZ3s7/W8pvHV/+R5TeapBs9rgKGMe8EBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADARNx/JTdwMcMneP916+kbezyvWZOz3/MaSfr87Bee15T94hnPa3L/x8ee1wCphisgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAENyPFFfXXB73fjHT/ja8lYJKBPfu3ez2vyX2VG4sCseAKCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwc1IEbPjT/yL5zXvLn8phiON8rxixd/ujOE4UufDWTGsCsd0LOBqxxUQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCm5FCw8aOjWnd00+95XlNwXDvNxaNxSfrvhnTuqw/N8R3EACD4goIAGCCAAEATHgKUFVVle644w6lp6crJydHCxcuVFNTU9Q+p0+fVnl5ucaMGaPrrrtOixcvVkdHR1yHBgAkP08Bqq+vV3l5ufbs2aOdO3eqr69Pc+fOVU9PT2SfVatW6b333tM777yj+vp6HTt2TIsWLYr74ACA5ObpQwg7duyI+rqmpkY5OTlqbGzUrFmz1NXVpV/96lfauHGj7rnnHknShg0b9I1vfEN79uzRd77znfhNDgBIapf1HlBXV5ckKSvr3K8xbmxsVF9fn0pKSiL7TJkyRePHj1dDw8CfLurt7VU4HI7aAACpL+YA9ff3a+XKlZo5c6amTp0qSWpvb9fIkSOVmZkZtW9ubq7a29sH/D5VVVUKBAKRLT8/P9aRAABJJOYAlZeX69ChQ9q8efNlDVBZWamurq7I1traelnfDwCQHGL6i6grVqzQ9u3btXv3bo0bNy7yeDAY1JkzZ3TixImoq6COjg4Fg8EBv5ff75ff749lDABAEvN0BeSc04oVK7Rlyxbt2rVLBQUFUc9Pnz5dI0aMUG1tbeSxpqYmHT16VMXFxfGZGACQEjxdAZWXl2vjxo3atm2b0tPTI+/rBAIBjR49WoFAQI8++qgqKiqUlZWljIwMPfnkkyouLuYTcACAKJ4CtG7dOknS7Nmzox7fsGGDli5dKkn65S9/qbS0NC1evFi9vb0qLS3V66+/HpdhAQCpw1OAnHOX3GfUqFGqrq5WdXV1zEPhyvrbQzfHtO6/XLfj0jsZOZPhsx4BwCVwLzgAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYiOk3oiK1pPXFtq7PnfW8ZoRvmOc1vc77gN2TvM8mSQP/3l4AicAVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggpuRQjmvfxzTug0rJnlec21ar+c1v1z/r57X3PxKbP9MAK4croAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABPcjBQx+1+3jrkixwmKG4sCqYgrIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGDCU4Cqqqp0xx13KD09XTk5OVq4cKGampqi9pk9e7Z8Pl/U9vjjj8d1aABA8vMUoPr6epWXl2vPnj3auXOn+vr6NHfuXPX09ETtt2zZMrW1tUW2tWvXxnVoAEDy8/QbUXfs2BH1dU1NjXJyctTY2KhZs2ZFHr/mmmsUDAbjMyEAICVd1ntAXV1dkqSsrKyox998801lZ2dr6tSpqqys1KlTpwb9Hr29vQqHw1EbACD1eboC+mf9/f1auXKlZs6cqalTp0Yef+ihhzRhwgSFQiEdPHhQzz77rJqamvTuu+8O+H2qqqq0Zs2aWMcAACQpn3POxbJw+fLl+u1vf6uPPvpI48aNG3S/Xbt2ac6cOWpubtakSZMueL63t1e9vb2Rr8PhsPLz8zVbCzTcNyKW0QAAhr50farTNnV1dSkjI2PQ/WK6AlqxYoW2b9+u3bt3XzQ+klRUVCRJgwbI7/fL7/fHMgYAIIl5CpBzTk8++aS2bNmiuro6FRQUXHLNgQMHJEl5eXkxDQgASE2eAlReXq6NGzdq27ZtSk9PV3t7uyQpEAho9OjROnLkiDZu3Kh7771XY8aM0cGDB7Vq1SrNmjVL06ZNS8g/AAAgOXl6D8jn8w34+IYNG7R06VK1trbq+9//vg4dOqSenh7l5+frvvvu03PPPXfRnwP+s3A4rEAgwHtAAJCkEvIe0KValZ+fr/r6ei/fEgBwleJecAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE8OtBzifc06S9KX6JGc8DADAsy/VJ+kf/z0fzJALUHd3tyTpI71vPAkA4HJ0d3crEAgM+rzPXSpRV1h/f7+OHTum9PR0+Xy+qOfC4bDy8/PV2tqqjIwMowntcR7O4Tycw3k4h/NwzlA4D845dXd3KxQKKS1t8Hd6htwVUFpamsaNG3fRfTIyMq7qF9hXOA/ncB7O4Tycw3k4x/o8XOzK5yt8CAEAYIIAAQBMJFWA/H6/Vq9eLb/fbz2KKc7DOZyHczgP53Aezkmm8zDkPoQAALg6JNUVEAAgdRAgAIAJAgQAMEGAAAAmkiZA1dXVuvHGGzVq1CgVFRXpD3/4g/VIV9yLL74on88XtU2ZMsV6rITbvXu35s+fr1AoJJ/Pp61bt0Y975zTCy+8oLy8PI0ePVolJSU6fPiwzbAJdKnzsHTp0gteH/PmzbMZNkGqqqp0xx13KD09XTk5OVq4cKGampqi9jl9+rTKy8s1ZswYXXfddVq8eLE6OjqMJk6Mr3MeZs+efcHr4fHHHzeaeGBJEaC33npLFRUVWr16tT755BMVFhaqtLRUx48ftx7tirvtttvU1tYW2T766CPrkRKup6dHhYWFqq6uHvD5tWvX6tVXX9X69eu1d+9eXXvttSotLdXp06ev8KSJdanzIEnz5s2Len1s2rTpCk6YePX19SovL9eePXu0c+dO9fX1ae7cuerp6Ynss2rVKr333nt65513VF9fr2PHjmnRokWGU8ff1zkPkrRs2bKo18PatWuNJh6ESwIzZsxw5eXlka/Pnj3rQqGQq6qqMpzqylu9erUrLCy0HsOUJLdly5bI1/39/S4YDLqXXnop8tiJEyec3+93mzZtMpjwyjj/PDjn3JIlS9yCBQtM5rFy/PhxJ8nV19c75879ux8xYoR75513Ivv86U9/cpJcQ0OD1ZgJd/55cM657373u+6pp56yG+prGPJXQGfOnFFjY6NKSkoij6WlpamkpEQNDQ2Gk9k4fPiwQqGQJk6cqIcfflhHjx61HslUS0uL2tvbo14fgUBARUVFV+Xro66uTjk5OZo8ebKWL1+uzs5O65ESqqurS5KUlZUlSWpsbFRfX1/U62HKlCkaP358Sr8ezj8PX3nzzTeVnZ2tqVOnqrKyUqdOnbIYb1BD7mak5/v888919uxZ5ebmRj2em5urTz/91GgqG0VFRaqpqdHkyZPV1tamNWvW6K677tKhQ4eUnp5uPZ6J9vZ2SRrw9fHVc1eLefPmadGiRSooKNCRI0f0ox/9SGVlZWpoaNCwYcOsx4u7/v5+rVy5UjNnztTUqVMlnXs9jBw5UpmZmVH7pvLrYaDzIEkPPfSQJkyYoFAopIMHD+rZZ59VU1OT3n33XcNpow35AOEfysrKIn+eNm2aioqKNGHCBL399tt69NFHDSfDUPDAAw9E/nz77bdr2rRpmjRpkurq6jRnzhzDyRKjvLxchw4duireB72Ywc7DY489Fvnz7bffrry8PM2ZM0dHjhzRpEmTrvSYAxryP4LLzs7WsGHDLvgUS0dHh4LBoNFUQ0NmZqZuueUWNTc3W49i5qvXAK+PC02cOFHZ2dkp+fpYsWKFtm/frg8//DDq17cEg0GdOXNGJ06ciNo/VV8Pg52HgRQVFUnSkHo9DPkAjRw5UtOnT1dtbW3ksf7+ftXW1qq4uNhwMnsnT57UkSNHlJeXZz2KmYKCAgWDwajXRzgc1t69e6/618dnn32mzs7OlHp9OOe0YsUKbdmyRbt27VJBQUHU89OnT9eIESOiXg9NTU06evRoSr0eLnUeBnLgwAFJGlqvB+tPQXwdmzdvdn6/39XU1Lg//vGP7rHHHnOZmZmuvb3derQr6gc/+IGrq6tzLS0t7ve//70rKSlx2dnZ7vjx49ajJVR3d7fbv3+/279/v5PkXn75Zbd//37317/+1Tnn3M9+9jOXmZnptm3b5g4ePOgWLFjgCgoK3BdffGE8eXxd7Dx0d3e7p59+2jU0NLiWlhb3wQcfuG9961vu5ptvdqdPn7YePW6WL1/uAoGAq6urc21tbZHt1KlTkX0ef/xxN378eLdr1y63b98+V1xc7IqLiw2njr9LnYfm5mb34x//2O3bt8+1tLS4bdu2uYkTJ7pZs2YZTx4tKQLknHOvvfaaGz9+vBs5cqSbMWOG27Nnj/VIV9z999/v8vLy3MiRI90NN9zg7r//ftfc3Gw9VsJ9+OGHTtIF25IlS5xz5z6K/fzzz7vc3Fzn9/vdnDlzXFNTk+3QCXCx83Dq1Ck3d+5cN3bsWDdixAg3YcIEt2zZspT7n7SB/vkluQ0bNkT2+eKLL9wTTzzhrr/+enfNNde4++67z7W1tdkNnQCXOg9Hjx51s2bNcllZWc7v97ubbrrJ/fCHP3RdXV22g5+HX8cAADAx5N8DAgCkJgIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADAxP8DAfdsknhiFekAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train.iloc[0,1:].values.reshape(28,28)) # 取第0行的第一列（pixel0开始）往后的数，reshape成28*28打印"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178b5f3b",
   "metadata": {},
   "source": [
    "查看shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1a4fc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36b31ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "\n",
       "[2 rows x 784 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951416ad",
   "metadata": {},
   "source": [
    "submission 提交格式 \n",
    "\n",
    "imageid就是test中的序号，其实就是把test集中的数据预测出来放入submission的label中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ad5e9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      0\n",
       "1        2      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6adaef6",
   "metadata": {},
   "source": [
    "### 数据类型转换\n",
    "\n",
    "\n",
    "- csv读入的数据是DataFrame类型\n",
    "- 把csv中pixel部分数据取出来的数据转换成numpy类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "332ced0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train.iloc[:,1:].values.reshape(-1,28,28)\n",
    "train_labels = train.iloc[:,0].values\n",
    "test_images = test.iloc[:,0:].values.reshape(-1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "048d2965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f5322ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 28, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "deefed94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f090edb7",
   "metadata": {},
   "source": [
    "查看训练集的数据分布，均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e1ce006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3085401559245608"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.std()/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "932b9ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13101533792088266"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.mean()/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21ebdbe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15969587",
   "metadata": {},
   "source": [
    "## Image Augmentation\n",
    "\n",
    "1. 图片增强\n",
    "2. 图片尺寸 Resize\n",
    "3. 标准化 Normalize\n",
    "4. 匹配到模型的input format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05be07c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(image_size,train=True):\n",
    "    # 训练阶段使用\n",
    "    if train: \n",
    "        return A.Compose([\n",
    "#                     A.RandomCrop(width=22, height=22), # 随即裁剪 可能是版本和opencv的版本冲突\n",
    "                    A.HorizontalFlip(p=0.5), # 水平翻转\n",
    "                    A.VerticalFlip(p=0.5),   # 垂直翻转\n",
    "                    A.RandomBrightnessContrast(p=0.2), \n",
    "                    A.Resize(*image_size,interpolation=cv2.INTER_LANCZOS4), # 形状统一必不可少\n",
    "                    A.Normalize(0.1310,0.3085), # 标准化，\n",
    "                    ToTensorV2()  # 把数据转化为Pytorch格式\n",
    "                ])\n",
    "    # 测试阶段使用\n",
    "    else:\n",
    "         return A.Compose([\n",
    "                    A.Resize(*image_size,interpolation=cv2.INTER_LANCZOS4), # 取决于测试集的图片大小，如果和训练集一样大，可以不要\n",
    "                    A.Normalize(0.1310,0.3085), # 标准化\n",
    "                    ToTensorV2()  # 把数据转化为Pytorch格式\n",
    "                ])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7dc5c364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_transform = get_transform((28,28),True) # 这里是初始化一个图像变换算符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2f8a993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_transform(image = train_images[0]) # 传入train_images[0] 这个变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8133a91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = train_transform(image = train_images[0]) # 返回的是变换后的train_images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fa979e",
   "metadata": {},
   "source": [
    "数据增强后的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "253dfcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output['image'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b721230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output['image'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7cbb5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(output['image'].squeeze().numpy()) # 使用squeeze把数据维度中不存在的实际通道删去"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf0deeb",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f05f80b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniDataSet(Dataset):\n",
    "    \n",
    "    # 传入数据\n",
    "    def __init__(self,images,labels=None,transform=None):\n",
    "        self.images = images.astype(\"float32\") # 转化为floate方便后面计算\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "         \n",
    "    # 获取长度\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    # 提取列表数据\n",
    "    def __getitem__(self,idx):\n",
    "        ret = {}  # 返回是一个字典，包含变换后的图像数据与标签数据\n",
    "        img = self.images[idx]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(image=img)[\"image\"]\n",
    "        ret[\"image\"] = img\n",
    "        \n",
    "        # 假如输入是有label的\n",
    "        if self.labels is not None:\n",
    "            ret[\"label\"] = self.labels[idx]\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6fbac827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = MiniDataSet(train_images,train_labels,get_transform((28,28),True)) # ds=字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7461a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于ds这个字典来说\n",
    "# ds[idx]返回一个字典对象\n",
    "# ds[idx][\"image\"]或者ds[idx][\"label\"]通过键访问该对象中的值\n",
    "\n",
    "#ds[0][\"image\"] # 取字典中的量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2565d0b",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "076dbba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniModel(nn.Module):\n",
    "    def __init__(self,backbone,num_class,pretrained=False,backbone_ckpt=None):\n",
    "        \n",
    "        # 写作规范\n",
    "        super().__init__() \n",
    "        self.backbone = timm.create_model(backbone,pretrained=pretrained,checkpoint_path=backbone_ckpt,in_chans=1)\n",
    "        # 模型做预训练默认三通道，我们的数据集只有单通道，所以需要加上通道数in_chans\n",
    "\n",
    "        # 定义自己的分类头\n",
    "        self.head = nn.Linear(self.backbone.get_classifier().in_features,num_class)# nn.Linear的输入维度可以看convnext_small原网络这层的输入\n",
    "        # 定义自己的分类层\n",
    "        self.backbone.head.fc = nn.Identity()\n",
    "        self.loss_fn = NLLLoss()\n",
    "        \n",
    "    \n",
    "    def forward(self,image,label=None):\n",
    "        embed = self.backbone(image) # 编码\n",
    "        logit = self.head(embed) # 分类\n",
    "        \n",
    "        if label is not None:\n",
    "            logit_logsoftmax = torch.log_softmax(logit,1)  #  预测  \n",
    "            loss = self.loss_fn( logit_logsoftmax,label)  # 损失函数\n",
    "            return {\"prediction\":logit,\"loss\":loss}\n",
    "        \n",
    "        return {\"prediction\" :logit}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0c74a4",
   "metadata": {},
   "source": [
    "- 因为28对于convnext_samll模型来说尺寸太小，所以在这里做图片尺寸缩放，在get_transform中变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "633f807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = MiniDataSet(train_images,train_labels,get_transform((224,224),True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10a0fddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MiniModel(\"convnext_small\",10,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21ff267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_images.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ed86659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds.images = ds.images.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1d5ffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds[0]['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54ab8889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds[0]['image'].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "339dc27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(ds[0]['image'].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cea6ad",
   "metadata": {},
   "source": [
    "查看网络的属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9227e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = timm.create_model(\"convnext_small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e808489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "865e9fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b7dc4a",
   "metadata": {},
   "source": [
    "查看线性层的输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80ea6ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.get_classifier().in_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "905af587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.head.fc = nn.Identity()  # 把net.head.fc层取出，令它等于一个恒等层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b634cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d999f3",
   "metadata": {},
   "source": [
    "## Pipeline \n",
    "\n",
    "- train_fn\n",
    "- eval_fn\n",
    "- pred_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93bd9ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.train() # 模型转化为训练阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "39777a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model,optimizer,dataloader,device):\n",
    "    model.to(device) # 选择设备\n",
    "    model.train() # 开始训练模式\n",
    "    train_loss = []\n",
    "    \n",
    "    for batch in tqdm(dataloader):\n",
    "        output = model(batch[\"image\"].to(device),batch[\"label\"].to(device))\n",
    "        optimizer.zero_grad() # 清零梯度\n",
    "        output[\"loss\"].backward() # 计算梯度\n",
    "        optimizer.step() # 优化器更新\n",
    "        train_loss.append(output['loss'].item()) # item方法可以避免显卡被卡死\n",
    " \n",
    "    return np.mean(train_loss)  # 返回训练过程中的一个平均loss\n",
    "\n",
    "def eval_one_epoch(model,dataloader,device):\n",
    "    model.to(device) # 选择设备\n",
    "    model.eval() # 开始训练模式\n",
    "    eval_loss = []\n",
    "    \n",
    "    for step, batch in enumerate(dataloader):\n",
    "        output = model(batch[\"image\"].to(device),batch[\"label\"].to(device))\n",
    "        eval_loss.append(output['loss'].item()) # item方法可以避免显卡被卡死\n",
    " \n",
    "    return np.mean(eval_loss)  # 返回训练过程中的一个平均loss\n",
    "\n",
    "def predict(model,dataloader,device):\n",
    "    model.to(device) # 选择设备\n",
    "    model.eval() # 开始训练模式\n",
    "    predictions = []\n",
    "    \n",
    "    for step, batch in enumerate(dataloader):\n",
    "        output = model(batch[\"image\"].to(device))\n",
    "        prediction = torch.argmax(output['prediction'],1)\n",
    "        predictions.append(prediction.cpu()).numpy() # 保存数据\n",
    "        \n",
    "    predictions = np.concatenate(predictions,axis=0)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08013bee",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11b52f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = EasyDict({\n",
    "    \"backbone\":\"convnext_small\",\n",
    "    \"num_class\": 10,\n",
    "    \"image_size\":(32,32),\n",
    "    \"pretrained\":True,\n",
    "    \"epochs\":5,\n",
    "    \"batch_size\":256,\n",
    "    \"num_workers\":0,\n",
    "    \"device\":\"cpu\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5f428932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'convnext_small'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG.backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7964a8e0",
   "metadata": {},
   "source": [
    "数据集定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0e2c31c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = get_transform(CONFIG.image_size, True)\n",
    "valid_transform = get_transform(CONFIG.image_size, False)\n",
    "\n",
    "\n",
    "full_train_ds = MiniDataSet(train_images, train_labels, train_transform)\n",
    "train_ds = MiniDataSet(train_images[:40000], train_labels[:40000], train_transform)\n",
    "val_ds = MiniDataSet(train_images[40000:], train_labels[40000:], valid_transform)\n",
    "test_ds = MiniDataSet(test_images, transform=valid_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9fd6882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(full_train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfedaae",
   "metadata": {},
   "source": [
    "dataloader定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6c787fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_dl = DataLoader(full_train_ds, batch_size=CONFIG.batch_size, num_workers=CONFIG.num_workers, shuffle=True, drop_last=True)\n",
    "train_dl = DataLoader(train_ds, batch_size=CONFIG.batch_size, num_workers=CONFIG.num_workers, shuffle=True, drop_last=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=CONFIG.batch_size, num_workers=CONFIG.num_workers, shuffle=False, drop_last=False)\n",
    "test_dl = DataLoader(test_ds, batch_size=CONFIG.batch_size, num_workers=CONFIG.num_workers, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4ac754",
   "metadata": {},
   "source": [
    "model定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22a033e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MiniModel(backbone=CONFIG.backbone, num_class=CONFIG.num_class, pretrained=CONFIG.pretrained)\n",
    "optimizer = Adam(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4c84926b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x00000154C8259200>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters() # 包含网络的weight, bias,等"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdd8c8f",
   "metadata": {},
   "source": [
    "### 训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd2ee021",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [41:12<00:00, 15.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_1, train loss 1.6984, val loss 0.3675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [27:31<00:00, 10.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_2, train loss 0.6126, val loss 0.1959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [27:31<00:00, 10.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_3, train loss 0.5733, val loss 0.0875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [27:31<00:00, 10.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_4, train loss 0.5371, val loss 0.1070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [27:23<00:00, 10.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_5, train loss 0.5347, val loss 0.0833\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(CONFIG.epochs):\n",
    "    train_loss = train_one_epoch(model, optimizer, train_dl, CONFIG.device)\n",
    "    val_loss = eval_one_epoch(model, val_dl, CONFIG.device)\n",
    "    print(f\"Epoch_{epoch+1}, train loss {train_loss:.4f}, val loss {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c000b646",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_prediction = predict(model, val_dl, device=CONFIG.device)\n",
    "test_prediction = predict(model, test_dl, device=CONFIG.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1834ee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c26c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(train_labels[40000:], val_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bb5dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"Label\"] = test_prediction\n",
    "submission.to_csv(\"./submit.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4289fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nbTranslate": {
   "displayLangs": [
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
