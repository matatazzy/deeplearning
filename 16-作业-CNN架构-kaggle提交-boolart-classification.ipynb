{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-05T04:21:58.183155Z",
     "iopub.status.busy": "2023-12-05T04:21:58.182735Z",
     "iopub.status.idle": "2023-12-05T04:21:58.555973Z",
     "shell.execute_reply": "2023-12-05T04:21:58.555037Z",
     "shell.execute_reply.started": "2023-12-05T04:21:58.183123Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T04:21:58.558150Z",
     "iopub.status.busy": "2023-12-05T04:21:58.557747Z",
     "iopub.status.idle": "2023-12-05T04:22:04.999699Z",
     "shell.execute_reply": "2023-12-05T04:22:04.998697Z",
     "shell.execute_reply.started": "2023-12-05T04:21:58.558123Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from easydict import EasyDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy as sp\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold  # 交叉验证\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import timm\n",
    "\n",
    "#import loss_func\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T04:22:05.001914Z",
     "iopub.status.busy": "2023-12-05T04:22:05.001273Z",
     "iopub.status.idle": "2023-12-05T04:22:05.007614Z",
     "shell.execute_reply": "2023-12-05T04:22:05.006490Z",
     "shell.execute_reply.started": "2023-12-05T04:22:05.001886Z"
    }
   },
   "outputs": [],
   "source": [
    "CFG = EasyDict({\n",
    "    \"model_name\":\"resnet50\",\n",
    "    \"num_class\": 10,\n",
    "    \"image_size\":(32,32),\n",
    "    \"pretrained\":True,\n",
    "    \"epochs\":5,\n",
    "    \"batch_size\":64,\n",
    "    \"num_workers\":2,\n",
    "    \"device\":torch.device('cuda'),\n",
    "    \"size_h\": 32,\n",
    "    \"size_w\": 32,\n",
    "    \"lr\":3e-4,\n",
    "    \"weight_decay\":1e-6,\n",
    "    \n",
    "})\n",
    "OUTPUT_DIR = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T04:22:05.010393Z",
     "iopub.status.busy": "2023-12-05T04:22:05.010071Z",
     "iopub.status.idle": "2023-12-05T04:22:05.066029Z",
     "shell.execute_reply": "2023-12-05T04:22:05.065100Z",
     "shell.execute_reply.started": "2023-12-05T04:22:05.010368Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/boolart-image-classification/train.csv\")\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T04:22:05.067465Z",
     "iopub.status.busy": "2023-12-05T04:22:05.067182Z",
     "iopub.status.idle": "2023-12-05T04:22:05.076804Z",
     "shell.execute_reply": "2023-12-05T04:22:05.075661Z",
     "shell.execute_reply.started": "2023-12-05T04:22:05.067441Z"
    }
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Dataset \n",
    "# ====================================================\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self,df,transform=None):\n",
    "        self.df = df\n",
    "        self.file_names = df['id'].values # 获取图片文件名\n",
    "        self.labels = df['target'].values # 获取训练集图片target值\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):  # len(train_dataset) 调用\n",
    "        return len(self.df)\n",
    "    \n",
    "    # 读取图片\n",
    "    def __getitem__(self,idx): # 这里的idx如何读取呢？---通过 [num] 正常传入序号\n",
    "        self.file_path = f'/kaggle/input/boolart-image-classification/train_image/{self.file_names[idx]}.jpg' # 读取图片地址\n",
    "        image = np.array(Image.open(self.file_path).convert(\"RGB\"))\n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)['image']\n",
    "        else:\n",
    "            image = cv2.resize(image,(CFG.size_h,CFG.size_w)) # 和原码不一样\n",
    "#             image = image[np.newaxis,:,:] # 添加一个新的轴\n",
    "            image = torch.from_numpy(image).float() #  ndarray -> pytorch\n",
    "            \n",
    "        label = torch.tensor(self.labels[idx]).long() # tensor\n",
    "        \n",
    "        return image/255, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T04:22:05.078848Z",
     "iopub.status.busy": "2023-12-05T04:22:05.078433Z",
     "iopub.status.idle": "2023-12-05T04:22:05.092691Z",
     "shell.execute_reply": "2023-12-05T04:22:05.091793Z",
     "shell.execute_reply.started": "2023-12-05T04:22:05.078814Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_transform(*,data):\n",
    "    if data == 'train':\n",
    "        return A.Compose([\n",
    "            \n",
    "            A.Resize(CFG.size_w, CFG.size_h),\n",
    "            A.HorizontalFlip(p=0.5), # 水平翻转\n",
    "            A.VerticalFlip(p=0.5),   # 垂直翻转\n",
    "#             A.RandomBrightnessContrast(p=0.2), \n",
    "            ToTensorV2()  # 把数据转化为Pytorch格式\n",
    "        ])\n",
    "    elif data == 'valid':\n",
    "        return A.Compose([\n",
    "            A.Resize(CFG.size_w, CFG.size_h),\n",
    "            ToTensorV2()  # 把数据转化为Pytorch格式\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T04:22:05.094843Z",
     "iopub.status.busy": "2023-12-05T04:22:05.094446Z",
     "iopub.status.idle": "2023-12-05T04:22:05.114356Z",
     "shell.execute_reply": "2023-12-05T04:22:05.113267Z",
     "shell.execute_reply.started": "2023-12-05T04:22:05.094810Z"
    }
   },
   "outputs": [],
   "source": [
    "full_train_ds = TrainDataset(train)\n",
    "train_ds = TrainDataset(train[:28440],transform=get_transform(data='train'))\n",
    "valid_ds   = TrainDataset(train[28440:],transform=get_transform(data='valid'))\n",
    "\n",
    "train_loader = DataLoader(train_ds,batch_size=CFG.batch_size,pin_memory=True,drop_last=False)\n",
    "valid_loader = DataLoader(valid_ds,batch_size=CFG.batch_size*2,pin_memory=True,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T04:22:05.116236Z",
     "iopub.status.busy": "2023-12-05T04:22:05.115789Z",
     "iopub.status.idle": "2023-12-05T04:22:10.809079Z",
     "shell.execute_reply": "2023-12-05T04:22:10.808141Z",
     "shell.execute_reply.started": "2023-12-05T04:22:05.116201Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_images(imgs,num_rows,num_cols,titles=None,scale=1.5):\n",
    "    figsize = (num_cols*scale,num_rows*scale)\n",
    "    \n",
    "    # 创建一个包含 num_rows行，num_cols列 的子图， figsize是显示绘图窗口的大小\n",
    "    _,axes = plt.subplots(num_rows,num_cols,figsize=figsize)  # axes 轴\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (ax,img) in enumerate(zip(axes,imgs)): # ax-一张图的轴 img-一张图的数据值\n",
    "        if torch.is_tensor(img):\n",
    "            # 图片张量\n",
    "            img = img.permute(1,2,0).numpy()*255\n",
    "            ax.imshow(img.astype(np.uint8))\n",
    "        else:                \n",
    "            # PIL图片--这个数据集\n",
    "            ax.imshow(img) # 把img画在ax底图上\n",
    "        ax.axes.get_xaxis().set_visible(False) # set_visible(False) 隐藏坐标轴\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "        ax.set_title(y[i].item()) # 迭代y 在一个batch_size中\n",
    "    return axes\n",
    "\n",
    "X, y = next(iter(train_loader))  # X 为一个batch_size的图片的array， y为label\n",
    "show_images(X, 8, 8, y) # 显示一个batch_size,且返回值为axes的值，也就是下面这些图片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T04:22:10.810918Z",
     "iopub.status.busy": "2023-12-05T04:22:10.810387Z",
     "iopub.status.idle": "2023-12-05T04:22:10.824092Z",
     "shell.execute_reply": "2023-12-05T04:22:10.823042Z",
     "shell.execute_reply.started": "2023-12-05T04:22:10.810887Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.model = timm.create_model(self.cfg.model_name, pretrained=pretrained, in_chans=3)\n",
    "        #print(self.model)\n",
    "        \n",
    "        if 'efficientnet' in self.cfg.model_name:\n",
    "            self.n_features = self.model.classifier.in_features\n",
    "            self.model.global_pool = nn.Identity()\n",
    "            self.model.classifier = nn.Identity()\n",
    "            \n",
    "        elif 'resnet' in self.cfg.model_name:\n",
    "            self.n_features = self.model.fc.in_features\n",
    "            self.model.global_pool = nn.Identity()\n",
    "            self.model.fc = nn.Identity()\n",
    "            \n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "                            #nn.Conv2d(self.n_features, self.n_features // 8, 1),\n",
    "                            #nn.LeakyReLU(),\n",
    "                            #nn.BatchNorm2d(self.n_features // 8),\n",
    "                            nn.Conv2d(self.n_features, 44, 1),\n",
    "                            #nn.Sigmoid()\n",
    "                        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs = x.size(0) # 返回x的batch_size\n",
    "        features = self.model(x)\n",
    "        pool_feature = self.pooling(features)\n",
    "        output = self.classifier(pool_feature).view(bs, -1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义训练和验证流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T04:22:10.828563Z",
     "iopub.status.busy": "2023-12-05T04:22:10.828203Z",
     "iopub.status.idle": "2023-12-05T04:22:10.839894Z",
     "shell.execute_reply": "2023-12-05T04:22:10.839106Z",
     "shell.execute_reply.started": "2023-12-05T04:22:10.828532Z"
    }
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# train,valid\n",
    "# ====================================================\n",
    "def train_fn(model,optimizer,train_loader,criterion,device):\n",
    "    \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    \n",
    "    for step, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        \n",
    "        y_preds = model(images)\n",
    "        loss = criterion(y_preds,labels)\n",
    "        \n",
    "        optimizer.zero_grad() # 清零梯度\n",
    "        loss.backward() # 计算梯度\n",
    "        \n",
    "        optimizer.step() # 优化器更新 \n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "    return np.mean(train_loss)\n",
    " \n",
    "def valid_fn(model,valid_loader,criterion,device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    eval_loss = []\n",
    "    \n",
    "    for step, (images, labels) in enumerate(valid_loader):\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        output = model(images)\n",
    "        \n",
    "        loss = criterion(output,labels.long())\n",
    "        eval_loss.append(loss.item())\n",
    "        \n",
    "    return np.mean(eval_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T04:22:10.842184Z",
     "iopub.status.busy": "2023-12-05T04:22:10.841218Z",
     "iopub.status.idle": "2023-12-05T04:22:11.766044Z",
     "shell.execute_reply": "2023-12-05T04:22:11.765164Z",
     "shell.execute_reply.started": "2023-12-05T04:22:10.842151Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "model = CustomModel(CFG,pretrained=True)\n",
    "optimizer = Adam(model.parameters(), lr=CFG.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T04:22:11.767670Z",
     "iopub.status.busy": "2023-12-05T04:22:11.767306Z",
     "iopub.status.idle": "2023-12-05T04:22:11.772685Z",
     "shell.execute_reply": "2023-12-05T04:22:11.771748Z",
     "shell.execute_reply.started": "2023-12-05T04:22:11.767637Z"
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = ',/'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T04:22:11.774654Z",
     "iopub.status.busy": "2023-12-05T04:22:11.774284Z",
     "iopub.status.idle": "2023-12-05T04:29:22.442991Z",
     "shell.execute_reply": "2023-12-05T04:29:22.442053Z",
     "shell.execute_reply.started": "2023-12-05T04:22:11.774622Z"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(CFG.epochs):\n",
    "    train_loss = train_fn(model,optimizer,train_loader,criterion,CFG.device)\n",
    "    val_loss   = valid_fn(model,valid_loader,criterion,CFG.device)\n",
    "    print(f\"Epoch: {epoch+1},train loss: {train_loss:.4f},val loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练文件保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T04:30:17.535353Z",
     "iopub.status.busy": "2023-12-05T04:30:17.534952Z",
     "iopub.status.idle": "2023-12-05T04:30:17.631009Z",
     "shell.execute_reply": "2023-12-05T04:30:17.630219Z",
     "shell.execute_reply.started": "2023-12-05T04:30:17.535326Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save({'model': model.state_dict()},OUTPUT_DIR + f'{CFG.model_name}_best_score.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T04:50:53.292326Z",
     "iopub.status.busy": "2023-12-05T04:50:53.291938Z",
     "iopub.status.idle": "2023-12-05T04:50:53.305696Z",
     "shell.execute_reply": "2023-12-05T04:50:53.304830Z",
     "shell.execute_reply.started": "2023-12-05T04:50:53.292299Z"
    }
   },
   "outputs": [],
   "source": [
    "test = '../input/boolart-image-classification/test_image/'\n",
    "test_data = pd.read_csv(\"/kaggle/input/boolart-image-classification/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T04:50:53.837581Z",
     "iopub.status.busy": "2023-12-05T04:50:53.837210Z",
     "iopub.status.idle": "2023-12-05T04:50:53.851593Z",
     "shell.execute_reply": "2023-12-05T04:50:53.850632Z",
     "shell.execute_reply.started": "2023-12-05T04:50:53.837552Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T04:51:04.676614Z",
     "iopub.status.busy": "2023-12-05T04:51:04.676027Z",
     "iopub.status.idle": "2023-12-05T04:51:04.683825Z",
     "shell.execute_reply": "2023-12-05T04:51:04.682913Z",
     "shell.execute_reply.started": "2023-12-05T04:51:04.676587Z"
    }
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self,df,transform=None):\n",
    "        self.df = df['id'].values\n",
    "        self.transform=transform\n",
    "     \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        self.file_path = test + f\"{self.df[idx]}.jpg\"\n",
    "        image = np.array(Image.open(self.file_path).convert(\"RGB\"))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)['image']\n",
    "        else:\n",
    "            image = image[np.newaxis,:,:]\n",
    "            image = torch.from_numpy(image).float()\n",
    "            \n",
    "        return image/255,self.df[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_loader加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T04:51:06.386443Z",
     "iopub.status.busy": "2023-12-05T04:51:06.385956Z",
     "iopub.status.idle": "2023-12-05T04:51:06.392695Z",
     "shell.execute_reply": "2023-12-05T04:51:06.391799Z",
     "shell.execute_reply.started": "2023-12-05T04:51:06.386408Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(test_data,transform=get_transform(data='valid'))\n",
    "test_loader  = DataLoader(test_dataset,batch_size=CFG.batch_size,shuffle=False,\n",
    "                          num_workers=CFG.num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T05:08:04.580043Z",
     "iopub.status.busy": "2023-12-05T05:08:04.579650Z",
     "iopub.status.idle": "2023-12-05T05:08:04.589375Z",
     "shell.execute_reply": "2023-12-05T05:08:04.588309Z",
     "shell.execute_reply.started": "2023-12-05T05:08:04.580009Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model,models_path,test_loader,device):\n",
    "    \n",
    "    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    pre = []\n",
    "    image_id = []\n",
    "    for i, (images,img_ids) in tk0:\n",
    "        image_id += list(img_ids.numpy())\n",
    "        images = images.to(device)\n",
    "\n",
    "        for model_path in models_path:\n",
    "            model.load_state_dict(torch.load(model_path)['model'])\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "#                 y_pred = F.softmax(model(images)).to('cpu').numpy()\n",
    "                    y_pred = F.softmax(model(images),1)\n",
    "            y_preds = y_pred.to('cpu').numpy()\n",
    "        predictions = F.softmax(torch.from_numpy(y_preds),dim=1)\n",
    "        _,predict_y = torch.max(predictions,dim=1)\n",
    "        predict_y = np.array(predict_y).tolist()\n",
    "        pre += predict_y\n",
    "                \n",
    "#     for step, batch in enumerate(test_loader):\n",
    "#         output = model(batch[\"image\"].to(device))\n",
    "#         prediction = torch.argmax(output['prediction'],1)\n",
    "#             predictions.append(prediction.cpu()).numpy() # 预测数据\n",
    "        \n",
    "#         predictions = np.concatenate(predictions,axis=0)\n",
    "    return pre,image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T05:08:05.331386Z",
     "iopub.status.busy": "2023-12-05T05:08:05.330569Z",
     "iopub.status.idle": "2023-12-05T05:08:24.608022Z",
     "shell.execute_reply": "2023-12-05T05:08:24.606853Z",
     "shell.execute_reply.started": "2023-12-05T05:08:05.331348Z"
    }
   },
   "outputs": [],
   "source": [
    "# model_path = ['./tf_efficientnet_b2_fold0_best_score.pth']\n",
    "\n",
    "models_path = [OUTPUT_DIR + f'{CFG.model_name}_best_score.pth']\n",
    "predictions,img_id = predict(model,models_path, test_loader, CFG.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T05:08:29.436181Z",
     "iopub.status.busy": "2023-12-05T05:08:29.435325Z",
     "iopub.status.idle": "2023-12-05T05:08:29.512561Z",
     "shell.execute_reply": "2023-12-05T05:08:29.511691Z",
     "shell.execute_reply.started": "2023-12-05T05:08:29.436144Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"id\":img_id,\n",
    "    \"predict\":predictions\n",
    "})\n",
    "df.to_csv(\"./submission.csv\",index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 4070249,
     "sourceId": 37852,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
